---
title: "HARVARD EXTENSION SCHOOL"
subtitle: "EXT CSCI E-106 Model Data Class Project Template"
author:

- Preet Shah 


tags: [logistic, neuronal networks, etc..]
abstract: |
  This is the location for your abstract.

  It must consist of two paragraphs.
date: "`r format(Sys.time(), '%d %B %Y')`"
geometry: margin=1.3cm
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---
\newpage
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(olsrr)
library(car)
library(caret)
#library(tidyverse)
HouseSales<-read.csv("KC_House_Sales.csv")
```
```{r}
dispRegFunc <- function(reg, var.names=FALSE, wrap=0) {

  ## Set the line wrapping only if this is being knit as a pdf
  line.limit <- 0
  if (!is.null(knitr::current_input())) {
    if("pdf_document" %in% rmarkdown::all_output_formats(knitr::current_input())) {
       line.limit <- wrap
    }
  }
  ## Check to see if this is a cv.glmnet object or a lm or rlm object
  ifelse(class(reg) == "cv.glmnet",
         coefs <- predict(reg, s=reg$lambda.min, type="coefficients")[,1],
         coefs <- reg$coefficients)
  
  b0 = coefs[1]
  n <- length(coefs)
  my_formula <- paste0("Y = ", round(b0, digits = 6))
  for (i in 2:n) {
    ## Choose the +/- sign for the coefficient then remove it using abs()
    new.formula.term <- paste0(ifelse(coefs[i] < 0," - "," + "),
                         signif(abs(coefs[i]),6),
                         ifelse(var.names,paste0(" * ",names(coefs)[i]),
                         names(coefs)[i]))
    if (line.limit > 0) {
      if (line.limit <= nchar(my_formula) + nchar(new.formula.term)) {
        print(my_formula)
        my_formula <- new.formula.term
      } else {
        my_formula <- paste0(my_formula, new.formula.term)
      }
    }
    else {
      my_formula <- paste0(my_formula, new.formula.term)
    }
  }
  print(my_formula)
}
```

\newpage
## House Sales in King County, USA data to be used in the Final Project

| Variable| Description |
| :-------:| :------- |
| id| **Unique ID for each home sold (it is not a predictor)**    |
| date| *Date of the home sale*    |
| price| *Price of each home sold*    |
| bedrooms| *Number of bedrooms*    |
| bathrooms| *Number of bathrooms, where ".5" accounts for a bathroom with a toilet but no shower*    |
| sqft_living| *Square footage of the apartment interior living space*    |
| sqft_lot| *Square footage of the land space*    |
| floors| *Number of floors*    |
| waterfront| *A dummy variable for whether the apartment was overlooking the waterfront or not*    |
| view| *An index from 0 to 4 of how good the view of the property was*    |
| condition| *An index from 1 to 5 on the condition of the apartment,*    |
| grade| *An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 has a high-quality level of construction and design.*    |
| sqft_above| *The square footage of the interior housing space that is above ground level*    | 
| sqft_basement| *The square footage of the interior housing space that is below ground level*    |
| yr_built| *The year the house was initially built*    |
| yr_renovated| *The year of the houseâ€™s last renovation*    |
| zipcode| *What zipcode area the house is in*    |
| lat| *Latitude*    |
| long| *Longitude*    |
| sqft_living15| *The square footage of interior housing living space for the nearest 15 neighbors*    |
| sqft_lot15| *The square footage of the land lots of the nearest 15 neighbors*    |
\newpage
## Instructions:
0.  Join a team with your fellow students with appropriate size (Four Students total)
1.  Load and Review the dataset named "KC_House_Sales'csv
2.	Create the train data set which contains 70% of the data and use set.seed (1023). The remaining 30% will be your test data set.
3.	Investigate the data and combine the level of categorical variables if needed and drop variables as needed. For example, you can drop id, Latitude, Longitude, etc.
4.	Build a regression model to predict price. 
5.	Create scatter plots and a correlation matrix for the train data set. Interpret the possible relationship between the response.
6.	Build the best multiple linear models by using the stepwise selection method. Compare the performance of the best two linear models. 
7.	Make sure that model assumption(s) are checked for the final model. Apply remedy measures (transformation, etc.) that helps satisfy the assumptions. 
8.	Investigate unequal variances and multicollinearity. If necessary, apply remedial methods (WLS, Ridge, Elastic Net, Lasso, etc.). 
9.	Build an alternative model based on one of the following approaches to predict price: regression tree, NN, or SVM.  Check the applicable model assumptions. Explore using a logistic regression. 
10.	Use the test data set to assess the model performances from above.
11.	Based on the performances on both train and test data sets, determine your primary (champion) model and the other model which would be your benchmark model.


\newpage

## Executive Summary

This project focuses on developing a model to predict property prices in King County, WA. Several factors determine a property's attractiveness to real estate investors, including age, location, property size, condition, grade, and view, among others. These factors will be incorporated into the model development process to ascertain their relevance in predicting property prices within the county.

The process will involve data cleaning and exploration to identify irrelevant features. The plan includes building several models, checking them for compliance with regression model assumptions, and applying data transformations alongside remedial measures such as Box-Cox, Ridge, and Robust, as necessary. A Regression Tree model will be developed as a challenger to compare with linear models. Model performance will be assessed using metrics like R-squared, Mean Absolute Error, and Sum of Squared Error. The best model will be selected at the end.

Model development will be conducted in RStudio using the King County Housing dataset.


\newpage
## I. Introduction (5 points)

This article centers on exploring the KC_house_sales dataset, which comprises over 21,000 house sales in King County during 2014 and 2015. Our primary objective is to develop a predictive model capable of estimating home prices for new sales in the region, targeting homes with six rooms or fewer.

Problem Statement and Purpose: The central problem is predicting home prices in King County, focusing specifically on smaller homes. The model aims to provide a valuable tool for stakeholders in the real estate market, enabling informed decisions about property transactions in the area.

Data Exploration and Cleaning: The initial phase involves thorough data quality exploration and basic cleaning procedures to ensure the dataset's reliability and accuracy, setting the stage for subsequent analysis and model development.

Data Splitting: The dataset is divided into a training set (30%) and a test set (70%). This division allows for model development on the training set and rigorous performance evaluation on the independent test set.

Model Building: Our approach begins with constructing a basic multilinear regression model on the training data as a baseline. Depending on the data characteristics, transformations to address issues like skewness might be necessary. Methods such as ridge regression and the Box-Cox transformation may be applied to tackle challenges like multicollinearity, and non-significant features may be considered for removal.

Model Evaluation: The final phase involves testing our model against competing models, such as the regression tree, to validate our approach and provide insights into different modeling techniques' strengths and weaknesses in predicting home prices in King County.

Through this comprehensive process, we aim to contribute valuable insights to real estate analytics and decision-making in the King County housing market.


\newpage
## I. Description of the data and quality (15 points)

In this section, we comprehensively examine the KC_House_Sales dataset, with over 21,000 data points representing home sales in King County. Our goal is to assess data quality, identify potential issues, and understand the relationships between predictors and the response variable. We employ various statistical tests and extensive graphical analyses to uncover patterns and correlations within the dataset.

The KC_House_Sales dataset contains information on home sales in King County, encompassing over 21,000 data points. Initial exploration involves loading the data for a basic overview to understand its structure and features.
```{r}
# Load the dataset
kc_house_data <- read.csv("KC_House_Sales.csv")

# Display the top 5 elements of the dataset
head(kc_house_data, 5)
```
The price variable appears as a character type but logically should be continuous (numerical). For the most part our features with the exception of zip code are continuous and thus we will not be using dummy variables.

Before we can use prices however we need to convert it into a numerical format for proper analysis, ensuring to remove any non-numeric characters like commas and dollar signs. Similarly, the date variable is a character type but should be converted into a date format for any time-series analysis or extraction of components like sale month or year. 

```{r}
# Remove the 'id', Latitude, Longitude column as it is not a predictor
# Remove sqft_basement as it creates perfect multicollinearity
kc_house_data <- kc_house_data[, !(names(kc_house_data) %in% c("id", "lat", "long", "sqft_basement"))]

# Remove commas and dollar signs, and convert price to numeric
kc_house_data$price <- as.numeric(gsub("[,$]", "", kc_house_data$price))

# Check if any NaNs are produced in the price conversion
if (any(is.na(kc_house_data$price))) {
  print("NaNs were produced in the price conversion.")
}

# Convert 'date' from character to Date type
# Assuming the format is "yyyyMMddT000000" as per your output
kc_house_data$date <- as.Date(substr(kc_house_data$date, 1, 8), format = "%Y%m%d")

# Display the top 5 elements of the dataset
head(kc_house_data, 5)
```
Now that the price and date entries have been cleaned and correctly formatted, we can use it in our data modeling. 

```{r}
# Show the data dictionary (structure of the dataset)
str(kc_house_data)

# Show descriptive statistics for the dataset
summary(kc_house_data)
```
Based on the data dictionary and the above initial review, variables like bedrooms, bathrooms, sqft_living, floors, waterfront, view, condition, grade, sqft_above, sqft_basement, yr_built, yr_renovated, zipcode, sqft_living15, and sqft_lot15 may be relevant for modeling the price. Variables like id and date might be less relevant as predictors, and variables like lat, long are better represented as zip codes.

.

```{r}
# Create Train & Test dataset
set.seed(1023)
n <- dim(kc_house_data)[1]
IND=sample(c(1:n),n*0.7)
train_data <- kc_house_data[IND,]
test_data <- kc_house_data[-IND,]

# Checking the size of the datasets
nrow(train_data)  # Should be around 70% of the original data
nrow(test_data)   # Should be around 30% of the original data
```

Some features must be investigated for multicollinearity, such as sqft_living, sqft_above and sqft_living15. We do this by creating a correlation plot
```{r}
# Load necessary library
library(corrplot)

# Note that we will not be using scatter plots due to the data size. 
# Calculate the correlation matrix for train_data
corr_matrix <- cor(train_data[, sapply(train_data, is.numeric)])

# Setting graphical parameters for a larger plot
options(repr.plot.width = 19, repr.plot.height = 15)

# Visualize the correlation matrix with numerical values
corrplot(corr_matrix, method = "color", type = "upper", order = "hclust", 
         addCoef.col = "black", tl.col = "black", tl.srt = 65, number.cex = 0.5)
```

As a result of our correlation plot, we can see some features such as sqft_living, sqft_above and sqft_living15 are highly correlate which means that there is a possibility of collinearity. We will deal with this in the following section.

Another issue that can impact our model is skewness which we will handle later by transforming the data. In order to check for skewness we will visually check each of the features.

```{r}
#SETTING UP VARIABLES TO USE IN FOR LOOP
col_name <- list()
for(col in names(train_data)){
  col_name[[length(col_name) + 1]] <- col
}
counter <- 1;
width_list <- list(10000, 1, 100000, 1, 1, 100, 100, 1, 1, 1, 1, 1, 100, 100, 100, 100, 1000, 100000, .01, 1)

# CREATE HISTOGRAMS
library(ggplot2)

# Distribution of House Prices in train_data
ggplot(train_data, aes(x = price)) +
  geom_histogram(binwidth = 100000, fill = "blue", color = "black") +
  labs(title = "Distribution of House Prices", x = "Price ($)", y = "Frequency")

# Distribution of Living Area Square Footage (sqft_living)
ggplot(train_data, aes(x = sqft_living)) +
  geom_histogram(binwidth = 100, fill = "green", color = "black") +
  labs(title = "Distribution of Living Area Square Footage", x = "Square Footage (sqft)", y = "Frequency")

# Distribution of Lot Size in sq. ft.
ggplot(train_data, aes(x = sqft_lot)) +
  geom_histogram(binwidth = 2000, fill = "orange", color = "black") +
  labs(title = "Distribution of Lot Size in sq ft", x = "Square Footage (sqft)", y = "Frequency")

# Distribution of Bedrooms
ggplot(train_data, aes(x = bedrooms)) +
  geom_histogram(binwidth = 1, fill = "red", color = "black") +
  labs(title = "Distribution of Bedrooms", x = "Number of Bedrooms", y = "Frequency")

# Distribution of Bathrooms
ggplot(train_data, aes(x = bathrooms)) +
  geom_histogram(binwidth = 0.25, fill = "brown", color = "black") +
  labs(title = "Distribution of Bathrooms", x = "Number of Bathrooms", y = "Frequency")

# Distribution of Floors
ggplot(train_data, aes(x = floors)) +
  geom_histogram(binwidth = 1, fill = "purple", color = "black") +
  labs(title = "Distribution of Floors", x = "Number of Floors", y = "Frequency")
```

Upon visually inspecting each feature, it is evident that there is skewness in the predictor variable data. To address this skewness, we will implement a log transformation on the predictor variables.


\newpage
## III. Model Development Process (15 points)

In this section, we will discuss our process for developing our model. The data set, KC_House_Sales, will be divided into a training set (70% of the data) and a test set (30% of the data) to facilitate model development and evaluation. We begin by constructing a basic multilinear regression model using the training set as a baseline. We then evaluate th initial performance of the model and understanding the relationships between predictors and the response variable. This will let us know if we need to drop irrelevant or redundant variables that may not contribute to the model and if any remedial measures are needed.


```{r}

# Create Train & Test dataset
set.seed(1023)
n <- dim(kc_house_data)[1]
IND=sample(c(1:n),n*0.7)
train_data <- kc_house_data[IND,]
test_data <- kc_house_data[-IND,]

# Checking the size of the datasets
nrow(train_data)  # Should be around 70% of the original data
nrow(test_data)   # Should be around 30% of the original data
```

Dataset is now split between 15129 train data set (70% of the data set) and 6484 test data set (30% of the data set). A basic multilinear regression will be fitted to all the variables of the training set.

```{r}
# Build a regression model to predict price
model <- lm(price ~ ., data = train_data)

# Model Summary
summary(model)
```
```{r}
# List of predictor variables
predictor_vars <- c("bedrooms", "bathrooms", "sqft_living", "sqft_lot", "floors",
                    "waterfront", "view", "condition", "grade", "sqft_above",
                    "yr_built", "yr_renovated", "zipcode",
                    "sqft_living15", "sqft_lot15")
                    
                    
# Set up the plotting area
par(mfrow = c(3, 4)) # Adjust these values based on the number of predictor variables

# Loop through each predictor variable and create a scatter plot against price
for (var in predictor_vars) {
  # Create the scatter plot
  plot(train_data[[var]], train_data$price, 
       main = paste("Price vs", var),
       xlab = var, ylab = "Price", pch = 19, col = "blue")

  # Fit a linear model and add a regression line
  model <- lm(price ~ train_data[[var]], data = train_data)
  abline(model, col = "red")
}

# Reset the plotting area to default
par(mfrow = c(1, 1))
```

Upon examining the model summary we get the following observations: 

- bedrooms: Each additional bedroom is associated with a decrease of about $35,880 in the house price, all else being equal. Both scatter plots and correlations matrix indicates that the bedrooms have positive correlation with the price (0.31). This can be due to multiple factors like multicollinearity, non-linearity, or outliers. 

- sqft_lot: The coefficient for sqft_lot is positive but very small (0.1295), suggesting that increases in land space have a minimal impact on house price. In urban centers, where space is at a premium, larger lots might be highly valued. However, larger lots might often be associated with older properties, which could affect the overall house price. We might consider age of the house and the years since the last update to the home.

- floors: The coefficient for floors suggesting that additional floors don't value. Single family homes generally have higher prices and they generally have one or two floors. While two-story homes are often valued more due to larger living spaces, homes with more than two floors might resemble or might be townhomes, which may be seen as less desirable for certain demographics. 


```{r}
library(ggplot2)

# Distribution of House Prices in train_data
ggplot(train_data, aes(x = price)) +
  geom_histogram(binwidth = 100000, fill = "blue", color = "black") +
  labs(title = "Distribution of House Prices", x = "Price ($)", y = "Frequency")

# Distribution of Living Area Square Footage (sqft_living)
ggplot(train_data, aes(x = sqft_living)) +
  geom_histogram(binwidth = 100, fill = "green", color = "black") +
  labs(title = "Distribution of Living Area Square Footage", x = "Square Footage (sqft)", y = "Frequency")

# Distribution of Lot Size in sq. ft.
ggplot(train_data, aes(x = sqft_lot)) +
  geom_histogram(binwidth = 500, fill = "orange", color = "black") +
  labs(title = "Distribution of Lot Size in sq ft", x = "Square Footage (sqft)", y = "Frequency")

# Distribution of Bedrooms
ggplot(train_data, aes(x = bedrooms)) +
  geom_histogram(binwidth = 1, fill = "red", color = "black") +
  labs(title = "Distribution of Bedrooms", x = "Number of Bedrooms", y = "Frequency")

# Distribution of Bathrooms
ggplot(train_data, aes(x = bathrooms)) +
  geom_histogram(binwidth = 0.25, fill = "orange", color = "black") +
  labs(title = "Distribution of Bathrooms", x = "Number of Bathrooms", y = "Frequency")

# Distribution of Floors
ggplot(train_data, aes(x = floors)) +
  geom_histogram(binwidth = 1, fill = "orange", color = "black") +
  labs(title = "Distribution of Floors", x = "Number of Floors", y = "Frequency")
```

We further graphically explore the data giving us the following observations:

- House Prices: The distribution of house prices is right-skewed, indicating that most of the houses are in the lower price range with a few houses in the higher price range. This skewness suggests that outlier handling and transformation might be necessary for modeling.

- Living Area Square Footage (sqft_living): This distribution is also right-skewed. Very large living areas beyond about 6000 or 7000 sq ft aren't part of the same market as living areas below such square footage. Again segmentation and outlier handling will be essential.

- Lot Square Footage: This distribution is also skewed, with the majority below 10,000 sq ft and the long tail going to 1.65 million sq ft. The sqft_lot and price might vary by location (approximated by zipcode).
Bedrooms and Bathrooms: The majority of houses have 2-4 bedrooms and 1-3 bathrooms. These features are crucial in real estate valuation and are likely significant predictors of house prices. However, the long tail of the distribution has some homes with about 33 bedrooms and up to 8 bathrooms. Thease aren't the same market segment and will impact data modeling without outlier handling.

- Floors: The number of floors in the distribution doesn't exceed 3 and the vast majority of homes have only 1 or 2 floors. While creating dummy variables for different floor levels (e.g., 1, 2, 3 floors) to capture the distinct effects of each category is an option, let's come back to floors later if this variable becomes important to utilize.


```{r}
# Segmentation by number of bedrooms
bedroom_segment_1 <- subset(train_data, bedrooms <= 6)
bedroom_segment_2 <- subset(train_data, bedrooms > 6)

# Plotting the segments
plot(bedroom_segment_1$bedrooms, bedroom_segment_1$price, main="Price vs. Bedrooms (<= 6 Bedrooms)", xlab="Bedrooms", ylab="Price", col="blue", pch=19)
plot(bedroom_segment_2$bedrooms, bedroom_segment_2$price, main="Price vs. Bedrooms (> 6 Bedrooms)", xlab="Bedrooms", ylab="Price", col="red", pch=19)

# Segmentation by lot size
lotsize_segment_1 <- subset(train_data, sqft_lot <= 11000)
lotsize_segment_2 <- subset(train_data, sqft_lot > 11000)

# Plotting the segments
plot(lotsize_segment_1$sqft_lot, lotsize_segment_1$price, main="Price vs. Lot Size (<= 11,000 sq ft)", xlab="Lot Size", ylab="Price", col="blue", pch=19)
plot(lotsize_segment_2$sqft_lot, lotsize_segment_2$price, main="Price vs. Lot Size  (> 11,000 sq ft)", xlab="Lot Size", ylab="Price", col="red", pch=19)
```

Observations: 

- bedrooms: For homes with up to 6 bedrooms, the price increases with number of bedrooms. Beyond 6 bedrooms, the price doesn't increase or in some cases decreases with increase in bedrooms. Hence it is clear that different segments are represented in the data. 

- sqft_lot: Homes with lot size up to 11,000 have a different price trend than homes with lot sizes above 11,000.

```{r}
# Remove bedrooms > 6 house data
kc_house_data <- subset(kc_house_data, bedrooms <= 6)
```


Given these findings, apply transformations to skewed variables to reduce skewness and to stabilize the variance of residuals. Common transformations include log, square root, or Box-Cox transformations. In addition, normalized prices across all zip codes based on a central property of each zip code, might better represent the dataset. Finally, the date variable on its own isn't predictive. However, certain values derived from the date, such as years since the last update of the house could play a role. 

```{r}
# Add zip_median_price as a new variable
kc_house_data <- merge(kc_house_data, aggregate(price ~ zipcode, kc_house_data, median), by = "zipcode", all.x = TRUE)
names(kc_house_data)[which(names(kc_house_data) == "price.y")] <- "zip_median_price"

# Normalize Price (using Min-Max Scaling)
min_price <- min(kc_house_data$price)
max_price <- max(kc_house_data$price)
kc_house_data$normalized_price <- (kc_house_data$price - min_price) / (max_price - min_price)

# Calculate Years Since Last Update (until the date of the sale)
kc_house_data$date <- as.Date(kc_house_data$date, format = "%Y-%m-%d")  # ensure 'date' is in Date format
kc_house_data$yr_last_update <- with(kc_house_data, ifelse(yr_renovated == 0, as.numeric(format(date, "%Y")) - yr_built, as.numeric(format(date, "%Y")) - yr_renovated))

# Display the top 5 elements of the dataset with new variables
head(kc_house_data, 5)
```
```{r}
summary(kc_house_data$zip_median_price)
hist(kc_house_data$zip_median_price, col = "skyblue", main = "Histogram of zip_median_price", xlab = "zip_median_price")
```

We will remove the zipcodes with zip_median_price > 1000000 based on the histogram trend

```{r}
kc_house_data <- subset(kc_house_data, zip_median_price <= 1000000)
```

\newpage
## IV. Model Performance Testing (15 points)

*Use the test data set to assess the model performances. Here, build the best multiple linear models by using the stepwise both ways selection method. Compare the performance of the best two linear models. Make sure that model assumption(s) are checked for the final linear model. Apply remedy measures (transformation, etc.) that helps satisfy the assumptions. In particular you must deeply investigate unequal variances and multicollinearity. If necessary, apply remedial methods (WLS, Ridge, Elastic Net, Lasso, etc.). *

In this section, we focus on assessing the performance of our linear regression models using the test data set. Here, we build the best multiple linear models by using the step-wise both ways selection method and then compare the performance of the best two linear models. Afterwords we investigate unequal variances and multicollinearity and if necessary we will apply remedial methods. 
Again we split the data set into a training set and a test set.

```{r}
# Split the updated dataset into train and test sets again
set.seed(1023)
n <- dim(kc_house_data)[1]
IND=sample(c(1:n),n*0.7)
train_data <- kc_house_data[IND,]
test_data <- kc_house_data[-IND,]

# Checking the size of the datasets
nrow(train_data)  # Should be around 70% of the original data
nrow(test_data)   # Should be around 30% of the original data

# Define the full model with all expected predictors
full_model <- lm(price.x ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_living15 + sqft_lot15 + zip_median_price + yr_last_update, data = train_data)

# Check the model summary
summary(full_model)

```

From our previous section we can see that some variables: price.x, sqft_living, sqft_lot, sqft_above, sqft_living15, sqft_lot15, normalized_price, have skewness. We will transform these variables via log to achieve a more normal distribution.
```{r}
columns_to_log <- c("price.x", "sqft_living", "sqft_lot", "sqft_above", "sqft_living15", "sqft_lot15", "normalized_price")

# Create a new data frame with log-transformed columns
logged_df <- train_data  # Copy all columns from train_data to logged_df
logged_df[columns_to_log] <- log(train_data[columns_to_log])  # Take log of specific columns

#print(logged_df)
```

We will now check the linear regression model assumptions visually and apply the appropriate remedial measures if needed.

```{r}
#MODEL BUILT AFTER HAVING FIXED CERTAIN COLUMNS FOR SKEWNESS
logged_model <- lm(price.x ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_living15 + sqft_lot15 + zip_median_price + yr_last_update, data = logged_df)
par(mfrow = c(2,2))
plot(logged_model)
```
```{r}
residuals <- logged_model$residuals
boxplot(residuals,horizontal = TRUE, staplewex = 0.5, col = 5, xlab = "Regression Residuals")
```


First we check Check for Normality by looking for heavy tails on the QQPlot. We also used the shapiro test but couldn't due to the size of our sample. We check Homo/Heteroscedasticity by looking at Residuals vs Fitted graph. We can see that it has heteroscedasticity due to funnel shape.

Additionally we will run a Breuschâ€“Pagan test:

#-BP TEST-
#H0 = Homoscedasticity
#H1 = Heteroscedasticity
#P- value < 0.05 alpha; 
```{r}
library(lmtest)
bp_full <- bptest(logged_model, studentize = FALSE)
bp_full
round(bp_full$p.value,2)
```

Since our P value, 2.2e-16, is less then 0.05 we reject null and accept alternative which means model is suffering from heteroscedasticity. The results mean our model has unequal variances. This means we will need to run a Box-cox transform on our logged model. 

```{r}
options("scipen" = 10)
library(MASS)
```
```{r}
#set up parameters
par(mfrow = c(2,2))
#find optimal lambda with best range and store it
bc1<-boxcox(logged_model, lambda = seq(0,5, by = .025))
#Get optimal lambda
lambda <- bc1$x[which.max(bc1$y)]
lambda
```
```{r}
logged_model.bc <- lm((price.x)^lambda ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_living15 + sqft_lot15 + zip_median_price + yr_last_update, data = logged_df)
summary(logged_model.bc)
```


```{r}
par(mfrow = c(2,2))
plot(logged_model.bc)
boxplot(logged_model.bc$residuals, horizontal = TRUE, staplewex = 0.5, col = 5, xlab = "Regression Residuals")
```
Here we decided to remove all influential outliers, identified with Cook's Distance, from the logged data frame  to help fit the data better.
```{r}
#ols_plot_cooksd_chart(logged_model.bc)
#ols_plot_dffits(logged_model.bc)
```
```{r}
#CLEAN DATA OF OUTLIERS USING COOK'S 
# Calculate Cook's distance
cooksd <- cooks.distance(logged_model.bc)

# Set a threshold for influential points (adjust as needed)
threshold <- 4 / nrow(logged_df) #RANDOM

# Identify influential points
influential_points <- which(cooksd > threshold)

# Remove influential outliers from the original data
clean_data <- logged_df[-influential_points, ]

n <- dim(clean_data)[1]
IND=sample(c(1:n),n*0.7)
clean_train_data <- clean_data[IND,]
clean_test_data <- clean_data[-IND,]
```
```{r}
#TEST AGAIN
clean_model <- lm((price.x)^lambda ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_living15 + sqft_lot15 + zip_median_price + yr_last_update, data = clean_train_data)
summary(clean_model)
par(mfrow = c(2,2))
plot(clean_model)
```
From the now transformed model called "clean_model", we will now perform manual stepwise process removing in order of highest p-value.
First is 'sqft_living15' and second is 'sqft_above'. 

```{r}
clean_model.step1 <- lm(price.x^lambda ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade + sqft_above + sqft_lot15 + zip_median_price + yr_last_update, data = clean_train_data)
summary(clean_model.step1)

clean_model2 <- lm(price.x^lambda ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade +  + sqft_lot15 + zip_median_price + yr_last_update, data = clean_train_data)
summary(clean_model2)
par(mfrow = c(2,2))
plot (clean_model2)
```
Here we test again for issues with outliers/influential points and for homoscedasticity/heteroscedasticity.
Huber's model shows us that there was no signifcant change in the coefficients. Thus, outliers do not have significant impact on our model and Huber model will not be used. 
```{r}
### Cooks distance plot####
ols_plot_cooksd_bar(clean_model2)
#no issues

## Unequal Variances ###
ols_test_breusch_pagan(clean_model2)
#reject the null hypothesis,evidence of constant variance; homoscedasticity.


### Collinearity Diagnostics ###

library(MASS)
library(faraway)
vif(clean_model2)

# Huber robust regression method on the same variables selected above
stack.huber <- rlm(price.x^lambda ~ date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade +  + sqft_lot15 + zip_median_price + yr_last_update, data = clean_train_data)
summary(stack.huber)
#check impact of outliers by comparing coefficients

coeff1<-summary(clean_model2)$coefficients[,1]
coeff2<-summary(stack.huber)$coefficients[,1]
coeffs<-cbind(coeff1,coeff2)
coeffs

```


We now run a Ridge regression as a remedial method to if there is multiconllinearity.
Although none of the variables have a VIF > 10, there are potential variables that we want to address through ridge: "sqft_living" = 7.46, "sqft_lot" = 7.04, "sqft_above" = 6.47, "sqft_lot15" = 6.8.

#--CHECK FOR MULTICOLLINEARITY--
#VIF > 10 shows multicollinearity
#No predictors show this
```{r}
olsrr::ols_vif_tol(logged_model)
```

```{r}
x <- data.matrix(dplyr::select(clean_train_data, -price.x))
y <- clean_train_data$price.x
z<- data.matrix(dplyr::select(clean_test_data, -price.x))
w<- clean_test_data$price.x
#cross validate
full_model.ridge <- glmnet::cv.glmnet(x, y, alpha =0, nlambda =100, lambda.min.ratio=0.0001)
best.lambda.full_model.ridge <- full_model.ridge$lambda.min
plot(full_model.ridge)
```
```{r}
print(paste0("Ridge best lambda of ", round(best.lambda.full_model.ridge, digits = 3)))

dispRegFunc(full_model.ridge)

```


\newpage
## V. Challenger Models (15 points)

In this section, we explore regression trees as an alternative model to predict house prices and compute its performance along side the full model, cleaned model and the Ridge Regression model created as a Remedial Measure. We will measure the performances of these models by comparing their R-squared, SSE, and MAE.


As indicated in the Model Development Section, the models were trained using the log transformed predictors of the train data set. As the test data set was not part of the log transformation, we can either first log-transform the test data before prediction or transform the predicted values to have same data state. 


We set up our regression tree as the Challenger Model.
```{r}
set.seed(123)

#install.packages("rpart")
par(mfrow=c(1,1))
library(rpart)

m.rpart <- rpart(price.x ~ ., data = clean_train_data)
m.rpart
```
```{r}

library(rpart.plot)
rpart.plot(m.rpart, digits = 3)
```
```{r}
par(mfrow=c(1,1))
library(rpart)

m.rpart <- rpart(price.x ~ + zipcode + date + bedrooms + bathrooms + sqft_living + sqft_lot + floors + waterfront + view + condition + grade, data = clean_train_data)
m.rpart

library(rpart.plot)
rpart.plot(m.rpart, digits = 3)
```


===========================PERFORMANCE TESTING==================================

This section of code represents our performance test on our CLEANED MODEL.
```{r}
C_PredictedTest<-(predict(clean_model2,clean_train_data))^1/lambda
Clean_ModelTest1<-data.frame(obs = clean_train_data$price.x, pred=C_PredictedTest)
defaultSummary(Clean_ModelTest1)

Clean_PredictedTest<-predict(clean_model2,clean_test_data)^1/lambda
Clean_Model_Test<-data.frame(obs = clean_test_data$price.x, pred=Clean_PredictedTest)
defaultSummary(Clean_Model_Test)
C <- defaultSummary(Clean_Model_Test)
```
This section of code represents our performance test on our RIDGE REGRESSION.
```{r}
R_PredictedTest<-predict(full_model.ridge, s = best.lambda.full_model.ridge, newx = x)
Ridge_ModelTest2<-data.frame(obs = clean_train_data$price.x, pred=c(R_PredictedTest))
defaultSummary(Ridge_ModelTest2)


Ridge_PredictedTest<-predict(full_model.ridge, s = best.lambda.full_model.ridge, newx = z)
Ridge_Model_Test<-data.frame(obs = clean_test_data$price.x, pred=c(Ridge_PredictedTest))
defaultSummary(Ridge_Model_Test)
R <- defaultSummary(Ridge_Model_Test)
```


This section of code represents our performance test on our REGRESSION TREE.
```{r}
set.seed(123)
#regression tree on the test and train data
Tree_PredictedTest<-predict(m.rpart,clean_train_data)
Tree_ModelTest2<-data.frame(obs = clean_train_data$price.x, pred=Tree_PredictedTest)
defaultSummary(Tree_ModelTest2)

Reg_PredictedTest<-predict(m.rpart,clean_test_data)
Reg_Tree_Test<-data.frame(obs = clean_test_data$price.x, pred=Reg_PredictedTest)
defaultSummary(Reg_Tree_Test)
T <- defaultSummary(Reg_Tree_Test)
```


\newpage
## VI. Model Limitation and Assumptions (15 points)

*Based on the performances on both train and test data sets, determine your primary (champion) model and the other model which would be your benchmark model. Validate your models using the test sample. Do the residuals look normal? Does it matter given your technique? How is the prediction performance using Pseudo R^2, SSE, RMSE?  Benchmark the model against alternatives. How good is the relative fit? Are there any serious violations of the model assumptions? Has the model had issues or limitations that the user must know? (Which assumptions are needed to support the Champion model?)* 

By comparing the models that we had gotten from the previous tests we get the following chart.
```{r}
Table_Model <- data.frame(
  Clean_Model = C,
  Ridge_Model = R,
  Tree = T
)
Table_Model
```


When R-squared, SSE, and MAE are taken to account, it can be seen that the Ridge Regression Model has the highest R-sqaured value of 0.98251646, the least RMSE of 0.06 and the least MAE of 0.05. Based on this comparison, the Ridge Regression model is our best predictor model for price.


This code chunk compares the price predicted by the four models against the actual price. This is done by examining the first 15 values of the predictions. 
\
```{r}
# Actual Price
act <- head(test_data$price, 15)

# Clean Model Price
cp <- head(Clean_PredictedTest, 15)

# Ridge Tree Price 
rp <- head(exp(Ridge_PredictedTest), 15)
rp
# Regression Tree Price
tp <- head(exp(Reg_PredictedTest), 15)

# Creating predictiontable with explicit column names
predictiontable <- data.frame(
  Actual_Price = act,
  Clean_Price = cp,
  Ridge_Price = rp,
  Reg_Price = tp
)

# Printing the predictiontable
predictiontable
```

Similarly, as can be seen from the table comparing the various models' first 15 predicted prices, with the actual price of the test data, the Ridge Regression Model predicted price values that are closest to the actual prices than the other models. 

\newpage
## VII. Ongoing Model Monitoring Plan (5 points)

Informed by practices observed in real estate estimation platforms like Zillow and Redfin, our ongoing model monitoring plan integrates quantitative thresholds, triggers, and essential assumptions. Designed to maintain the model's accuracy and applicability over time, the plan considers potential expansions beyond the King County dataset and updates within it.

The monitoring components cover various aspects. Data drift monitoring sets thresholds for significant changes in key feature and target variable distributions, with a trigger for model reassessment if data drift exceeds predefined limits. Performance metrics, such as Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE), are monitored by establishing thresholds, with reevaluation triggers if metrics consistently deviate beyond acceptable limits, indicating a decline in predictive accuracy. Leading indicator shifts involve setting thresholds for statistically significant deviations in factors impacting real estate prices, with triggers for reassessing the model's sensitivity to external factors. Average price changes are monitored through set thresholds at both the overall market and specific segments, with triggers for model reassessment if there are sustained statistically significant deviations, indicating potential shifts in market dynamics.

Model replacement triggers include responses to drastic external changes, like black swan events or significant real estate developments, and an inability of the model to adapt to new data patterns or variables, leading to sustained declines in predictive accuracy. Key assumptions for continuous use include the assumption of data similarity, where new data patterns are akin to the original dataset, maintenance of feature relevance, stability in external factors impacting real estate prices, and the model's adaptability to new data patterns.

By integrating these monitoring components, replacement triggers, and key assumptions, the model remains dynamic, responsive, and accurate amidst evolving real estate market dynamics, ensuring its sustained relevance and effectiveness.

\newpage
## VIII. Conclusion (5 points)

*Summarize your results here. What is the best model for the data and why?*
The original dataset received for the project underwent cleaning to address irrelevant characters in the response variable, price, ensuring its numerical format. The date feature was converted to a date format, aiding in the derivation of a new variable, property age. Another new variable, zip_median_price, was introduced after identifying zipcode as a crucial predictor for price. Further exploration led to the reduction of variables either irrelevant to the model development or exhibiting multicollinearity, such as Id, lat, long, and sqft_basement.

Splitting the dataset into training and test sets, an initial full model was developed. This model required the log transformation of predictor variables to address skewness and a square transformation for Y based on the optimal lambda, resulting in another model, clean_model. Unlike the initial full model, clean_model underwent stepwise variable selection to retain only significant variables, leading to clean_model_2. Remedial measures like Ridge Regression and Weighted Least Squares were applied, with Ridge Regression emerging as the preferred option. A Regression Tree was also built for comparison with the linear models, culminating in a total of four different models.

These models were evaluated using SSE, MAE, and R-Squared metrics. The Ridge Regression model emerged as the best, with an R-Squared of 0.98, while the Regression Tree was the least performing model, with an R-Squared of 0.53.

## Bibliography (7 points)

- House sales in King County, USA. (2016, August 25). Kaggle. https://www.kaggle.com/datasets/harlfoxem/housesalesprediction

- How ML at Redfin is influencing the housing market. (2022, July 12). TWIML. https://twimlai.com/article/house-hunters-how-ml-at-redfin-is-influencing-the-housing-market-with-akshat-kaul/

- Kutner, M. H. (2005). Applied Linear Statistical Models. McGraw-Hill/Irwin.

## Appendix (3 points)

*Please add any additional supporting graphs, plots and data analysis.*
```{r}
#CODE FOR HISTOGRAM OF LOGGED DATAFRAME
library(ggplot2)
library(tidyr)
library(dplyr)

# Transform the dataset to long format, using all_of() for the selection
long_format_df <- gather(logged_df, key = "variable", value = "value", all_of(columns_to_log))

# Filter out non-finite values
long_format_df <- long_format_df %>%
  filter(is.finite(value))

# List of widths for histograms, adjust this list to match the number of variables
width_list <- list(1, 1, 1, 1, 1, 1, 1)

# Map the widths to the included variables
binwidth_map <- setNames(width_list, columns_to_log)

# Create a histogram for each variable
p <- ggplot(long_format_df, aes(x = value)) +
    facet_wrap(~variable, scales = "free") +
    labs(y = "Frequency")

for (var in columns_to_log) {
    p <- p + geom_histogram(data = subset(long_format_df, variable == var), 
                            aes(x = value), binwidth = binwidth_map[[var]], 
                            fill = "blue", color = "black")
}

# Print the plot
p
```
```{r}
#BOXPLOT FOR OUTLIERS OF LOGGED DATA
# Create a boxplot for each variable
p <- ggplot(long_format_df, aes(x = variable, y = value)) +
    geom_boxplot(fill = "blue", color = "black") +
    facet_wrap(~variable, scales = "free") +
    labs(x = "Variable", y = "Values")

# Print the plot
p
```

